{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48cde9f7-cf94-4c69-8b34-a5f72c58024e",
   "metadata": {},
   "source": [
    "# Pretraining (Masked LM + NSP)\n",
    "\n",
    "## PROCESS OVERVIEW\n",
    "\n",
    "\n",
    "\n",
    "| Step | Penjelasan                           | Status |\n",
    "| :--: | :----------------------------------- | :----: |\n",
    "|   1  | Bangun Mini-BERT Stack               |    âœ…   |\n",
    "|   2  | Pretraining (Masked LM + NSP)        |   NOW   |\n",
    "|   3  | Fine-tuning ke task spesifik         |   ðŸ”œ   |\n",
    "|   4  | Buat dataset dummy buat latihan      |   ðŸ”œ   |\n",
    "|   5  | Build mindset & intuition level dewa |   ðŸ”œ   |\n",
    "\n",
    "---\n",
    "\n",
    "INTI :\n",
    "\n",
    "- Input: Token yang di-mask sebagian + sepasang kalimat\n",
    "- Target 1: Isi kata yang di-mask\n",
    "- Target 2: Apakah kalimat kedua nyambung?\n",
    "\n",
    "HOW? :\n",
    "\n",
    "- Tokenisasi kalimat âž” jadi token ID\n",
    "\n",
    "- Tambahin [CLS] di awal, [SEP] antar kalimat\n",
    "\n",
    "- Tambahin Positional Encoding kayak biasa\n",
    "\n",
    "- Random pilih token buat di-[MASK] (sekitar 15% token)\n",
    "\n",
    "- Masukin ke Mini-BERT stack - model kita\n",
    "\n",
    "- Output 1: Prediksi isi token yang ketutup\n",
    "\n",
    "- Output 2: Prediksi label NSP (IsNext / NotNext)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Misi                              | Tujuan                         | Gampangnya                                     |\n",
    "| :-------------------------------- | :----------------------------- | :--------------------------------------------- |\n",
    "| 1. Masked Language Model (MLM)    | Belajar isi kata yang hilang   | Tebak kata yang ketutupan                      |\n",
    "| 2. Next Sentence Prediction (NSP) | Belajar hubungan antar kalimat | Tebak apakah kalimat kedua nyambung atau ngaco |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45eea8-0591-4067-b90d-c1141e3d5614",
   "metadata": {},
   "source": [
    "# MLM : MASK LANGUAGE MODEL\n",
    "\n",
    "\n",
    "## INTUITION\n",
    "\n",
    "- Belajar isi kata yang hilang, tutup beberapa kata dalam kalimat\n",
    "- Tebak kata yang ketutupan , suruh bert nebak itu\n",
    "- Kalimat asli:\n",
    "- \"Saya makan nasi di warung.\"\n",
    "\n",
    "- Setelah masking:\n",
    "- \"Saya [MASK] nasi di [MASK].\"\n",
    "\n",
    "- Tugas BERT:\n",
    "- Tebak [MASK] = \"makan\", [MASK] = \"warung\"\n",
    "\n",
    "\n",
    "## PROCESS\n",
    "\n",
    "1. Input :\n",
    "\n",
    "- c = ['kucing bermain di taman']\n",
    "\n",
    "- t = ['kucing', 'bermain', 'di', 'taman']\n",
    "\n",
    "\n",
    "2. Special Token :\n",
    "\n",
    "- ['[CLS]', 'kucing', 'bermain', 'di', 'taman', '[SEP]']\n",
    "\n",
    "\n",
    "3. Masking 15% Input :\n",
    "\n",
    "- ['[CLS]', 'kucing', '[MASK]', 'di', 'taman', '[SEP]']\n",
    "\n",
    "4. Pretrain Model with this Approach :\n",
    "\n",
    "- Input : ['[CLS]', 'kucing', '[MASK]', 'di', 'taman', '[SEP]']\n",
    "  \n",
    "- Embedding (token embedding + positional embedding),\n",
    "  \n",
    "- Stack Encoder stack (MHA âž” AddNorm âž” FFN âž” AddNorm),\n",
    "\n",
    "- keluar tensor representasi semua token.\n",
    "\n",
    "\n",
    "## PSEUDOCODE\n",
    "\n",
    "    # pretraining bert for mlm\n",
    "    initialize bert model with random weight\n",
    "\n",
    "    def apply mask (tokens):\n",
    "        for i in range (len token):\n",
    "            if random < 0.15:\n",
    "                if random < 0.8:\n",
    "                    tokens[i] = [mask]\n",
    "                elif random < 0.9:\n",
    "                    token[i] = random_token()\n",
    "                else:\n",
    "                    token[i] = token[i]\n",
    "                lebel[i] = original token\n",
    "            else:\n",
    "                label[i] = [ignore]\n",
    "\n",
    "        return tokens, label\n",
    "    \n",
    "    for each epoch:\n",
    "        for each batch in training data :\n",
    "        # 1. tokenize\n",
    "        input token = tokenize(batch)\n",
    "\n",
    "        # 2. masking\n",
    "        mask input, label = apply mask (input token)\n",
    "\n",
    "        # 3. feed forward bert\n",
    "        output = bertmodel(mask input)\n",
    "\n",
    "        # 4. training, loss \n",
    "        loss = cross entropy(output[mask position], labels[mask position])\n",
    "\n",
    "        # 5. backpropagation or update parameter\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero grad()\n",
    "\n",
    "\n",
    "## EXAMPLE\n",
    "\n",
    "1. Input : ['[CLS]', 'singa', 'berlari', 'cepat', '[SEP]']\n",
    "\n",
    "2. Mask :['[CLS]', 'singa', '[MASK]', 'cepat', '[SEP]']\n",
    "\n",
    "3. Embedding :\n",
    "\n",
    "- [CLS]:  [0.1, 0.2]\n",
    "\n",
    "- singa:  [0.5, 0.4]\n",
    "\n",
    "- [MASK]: [0.0, 0.0]  (karena belum tahu)\n",
    "\n",
    "- cepat:  [0.3, 0.7]\n",
    "\n",
    "- [SEP]:  [0.1, 0.2]\n",
    "\n",
    "\n",
    "4. BERT Model :\n",
    "\n",
    "- MHA âž” AddNorm\n",
    "\n",
    "- FFN âž” AddNorm\n",
    "\n",
    "- [MASK]: [0.48, 0.45]\n",
    "\n",
    "\n",
    "5. Loss :\n",
    "\n",
    "- Vocab :\n",
    "{\n",
    "  'singa':  [0.5, 0.4],\n",
    "  'berlari': [0.48, 0.45],\n",
    "  'cepat': [0.3, 0.7],\n",
    "  'makan': [0.7, 0.2]\n",
    "}\n",
    "\n",
    "- Similarity\n",
    "\n",
    "- ke 'singa' âž” 0.48Ã—0.5 + 0.45Ã—0.4 = 0.24 + 0.18 = 0.42\n",
    "\n",
    "- ke 'berlari' âž” 0.48Ã—0.48 + 0.45Ã—0.45 = 0.2304 + 0.2025 = 0.4329\n",
    "\n",
    "- ke 'cepat' âž” 0.48Ã—0.3 + 0.45Ã—0.7 = 0.144 + 0.315 = 0.459\n",
    "\n",
    "- ke 'makan' âž” 0.48Ã—0.7 + 0.45Ã—0.2 = 0.336 + 0.09 = 0.426\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "## NEXT SENTENCE PREDICTION (NSP)\n",
    "\n",
    "- Dikasih dua kalimat, suruh BERT tebak:\n",
    "\n",
    "- Nyambung? (A âž” B)\n",
    "\n",
    "- Atau ngaco? (A âž” random)\n",
    "\n",
    "- Kalimat 1: \"Saya pergi ke pasar.\"\n",
    "- Kalimat 2: \"Saya membeli buah.\"\n",
    "- ==> Label: IsNext (nyambung)\n",
    "\n",
    "- Kalimat 1: \"Saya pergi ke pasar.\"\n",
    "- Kalimat 2: \"Bulan purnama sangat indah.\"\n",
    "- ==> Label: NotNext (acak)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa36960",
   "metadata": {},
   "source": [
    "## PYTHON CODE IMPLEMENTATION OF PRETRAIN BERT MODEL\n",
    "\n",
    "src = https://www.101ai.net/text/bert\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed39225-2666-465f-8b9a-798ee265751d",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2c122dc3-6300-4260-b60d-819581c433ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'i', 'like', 'playing', 'pussies', '[MASK]', '[SEP]']"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "corpus = 'i like playing pussies'\n",
    "vocab = corpus.split()\n",
    "vocab.insert(0, '[CLS]')\n",
    "vocab.extend(['[MASK]', '[SEP]'])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "75401d71-61cd-4975-bd71-dde58d201483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[CLS]': 0, 'i': 1, 'like': 2, 'playing': 3, 'pussies': 4, '[MASK]': 5, '[SEP]': 6}\n",
      "\n",
      "{0: '[CLS]', 1: 'i', 2: 'like', 3: 'playing', 4: 'pussies', 5: '[MASK]', 6: '[SEP]'}\n"
     ]
    }
   ],
   "source": [
    "token2idx = {}\n",
    "idx2token = {}\n",
    "\n",
    "for idx, token in enumerate(vocab):\n",
    "    token2idx[token] = idx\n",
    "    idx2token[idx] = token\n",
    "\n",
    "print(token2idx)\n",
    "print()\n",
    "print(idx2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9ad4fbf1-44c9-4b0a-b7d8-5d65d593613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[CLS]': 0, 'i': 1, 'like': 2, 'playing': 3, 'pussies': 4, '[MASK]': 5, '[SEP]': 6}\n",
      "\n",
      "{0: '[CLS]', 1: 'i', 2: 'like', 3: 'playing', 4: 'pussies', 5: '[MASK]', 6: '[SEP]'}\n"
     ]
    }
   ],
   "source": [
    "token2idx = {token : idx for idx, token in enumerate(vocab)}\n",
    "idx2token = {idx : token for token, idx in token2idx.items()}\n",
    "\n",
    "print(token2idx)\n",
    "print()\n",
    "print(idx2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1af2f1",
   "metadata": {},
   "source": [
    "### Mask and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ede030ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'i', 'like', '[MASK]', 'pussies', '[SEP]']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = corpus.split()\n",
    "tokens.insert(0, '[CLS]')\n",
    "tokens.append('[SEP]')\n",
    "tokens[tokens.index('playing')] = '[MASK]'\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5a9b0a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 5, 4, 6]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = [token2idx[t] for t in tokens]\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b03cf-fb2f-4c36-8752-a8d449c6c25c",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "768ffdbd-2559-4eda-9ce0-318d3c9e79ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03745401, 0.09507143, 0.07319939, 0.05986585],\n",
       "       [0.01560186, 0.01559945, 0.00580836, 0.08661761],\n",
       "       [0.0601115 , 0.07080726, 0.00205845, 0.09699099],\n",
       "       [0.08324426, 0.02123391, 0.0181825 , 0.01834045],\n",
       "       [0.03042422, 0.05247564, 0.0431945 , 0.02912291],\n",
       "       [0.06118529, 0.01394939, 0.02921446, 0.03663618],\n",
       "       [0.045607  , 0.0785176 , 0.01996738, 0.05142344]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 0.1\n",
    "d_model = 4\n",
    "\n",
    "np.random.seed(42)\n",
    "embed_matrix = np.random.rand(len(vocab), d_model) * scale\n",
    "embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dff6cda4-93e9-47dd-900d-53dbe4824cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [CLS]\n",
      "ID   : 0\n",
      "Embed: [0.03745401 0.09507143 0.07319939 0.05986585]\n",
      "\n",
      "Token: i\n",
      "ID   : 1\n",
      "Embed: [0.01560186 0.01559945 0.00580836 0.08661761]\n",
      "\n",
      "Token: like\n",
      "ID   : 2\n",
      "Embed: [0.0601115  0.07080726 0.00205845 0.09699099]\n",
      "\n",
      "Token: [MASK]\n",
      "ID   : 5\n",
      "Embed: [0.06118529 0.01394939 0.02921446 0.03663618]\n",
      "\n",
      "Token: pussies\n",
      "ID   : 4\n",
      "Embed: [0.03042422 0.05247564 0.0431945  0.02912291]\n",
      "\n",
      "Token: [SEP]\n",
      "ID   : 6\n",
      "Embed: [0.045607   0.0785176  0.01996738 0.05142344]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_matrixs = []\n",
    "for token, its_id in zip(tokens, token_ids):\n",
    "    print(f\"Token: {token}\")\n",
    "    print(f\"ID   : {its_id}\")\n",
    "    print(f\"Embed: {embed_matrix[its_id]}\\n\")\n",
    "    embed_matrixs.append(embed_matrix[its_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c75039-b2ab-402c-9b28-d4cf3b8b07d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c5e6dd4-a9a3-4c73-a67b-26c1bc6e6512",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "73af26bb-7edc-44ec-a3ac-e49c1bbe11e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]]),\n",
       " array([1, 2, 3]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ids = len(token_ids) + 1\n",
    "\n",
    "pos = np.arange(len_ids).reshape(len_ids,1)\n",
    "i = np.arange(1,d_model)\n",
    "\n",
    "pos, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e0492996-14ba-4fc8-8b30-f8cd97dac472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   0.01 0.01]\n",
      "\n",
      "[[0.   0.   0.  ]\n",
      " [1.   0.01 0.01]\n",
      " [2.   0.02 0.02]\n",
      " [3.   0.03 0.03]\n",
      " [4.   0.04 0.04]\n",
      " [5.   0.05 0.05]\n",
      " [6.   0.06 0.06]]\n"
     ]
    }
   ],
   "source": [
    "angle_rates = 1 / np.power(10000, (2*(i//2))/4)\n",
    "angle_rads = pos * angle_rates\n",
    "\n",
    "\n",
    "print(angle_rates)\n",
    "print()\n",
    "print(angle_rads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd880391-590c-4c76-952e-9a70fc3dfba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding = np.zeros((len_ids, d_model))\n",
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7d483d7c-be82-4c10-805b-5af22033fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.84147098,  0.        ,  0.00999983,  0.        ],\n",
       "       [ 0.90929743,  0.        ,  0.01999867,  0.        ],\n",
       "       [ 0.14112001,  0.        ,  0.0299955 ,  0.        ],\n",
       "       [-0.7568025 ,  0.        ,  0.03998933,  0.        ],\n",
       "       [-0.95892427,  0.        ,  0.04997917,  0.        ],\n",
       "       [-0.2794155 ,  0.        ,  0.05996401,  0.        ]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c57eed14-2645-41af-afa1-7672e01b9407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
       "       [ 0.84147098,  0.99995   ,  0.00999983,  0.99995   ],\n",
       "       [ 0.90929743,  0.99980001,  0.01999867,  0.99980001],\n",
       "       [ 0.14112001,  0.99955003,  0.0299955 ,  0.99955003],\n",
       "       [-0.7568025 ,  0.99920011,  0.03998933,  0.99920011],\n",
       "       [-0.95892427,  0.99875026,  0.04997917,  0.99875026],\n",
       "       [-0.2794155 ,  0.99820054,  0.05996401,  0.99820054]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "98057786-82dd-4062-92d6-682830337ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_encoding), len(embed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ca70555b-fc06-43f2-a55c-c7184a7f4736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = pos_encoding + embed_matrix\n",
    "input_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca1f0b-c947-4af9-addb-f2d7da0ce469",
   "metadata": {},
   "source": [
    "### Single Head Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bc0860eb-45bf-4479-b46f-780bc175f959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.05488135, 0.07151894, 0.06027634, 0.05448832],\n",
       "        [0.04236548, 0.06458941, 0.04375872, 0.0891773 ],\n",
       "        [0.09636628, 0.03834415, 0.0791725 , 0.05288949],\n",
       "        [0.05680446, 0.09255966, 0.00710361, 0.00871293]]),\n",
       " array([[0.00202184, 0.08326198, 0.07781568, 0.08700121],\n",
       "        [0.09786183, 0.07991586, 0.04614794, 0.07805292],\n",
       "        [0.01182744, 0.0639921 , 0.01433533, 0.09446689],\n",
       "        [0.05218483, 0.04146619, 0.02645556, 0.07742337]]),\n",
       " array([[0.04561503, 0.05684339, 0.00187898, 0.06176355],\n",
       "        [0.06120957, 0.0616934 , 0.09437481, 0.06818203],\n",
       "        [0.03595079, 0.0437032 , 0.06976312, 0.00602255],\n",
       "        [0.06667667, 0.06706379, 0.02103826, 0.01289263]]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 0.1\n",
    "\n",
    "np.random.seed(0)\n",
    "wq = np.random.rand(d_model, d_model) * scale\n",
    "wk = np.random.rand(d_model, d_model) * scale\n",
    "wv = np.random.rand(d_model, d_model) * scale\n",
    "\n",
    "wq, wk, wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d10dc673-527a-404c-a61d-28016b4f653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.11570781, 0.17431629, 0.06350076, 0.11280234],\n",
       "        [0.15330681, 0.22806917, 0.10507048, 0.14756769],\n",
       "        [0.16298744, 0.24084536, 0.11481831, 0.15901818],\n",
       "        [0.11802287, 0.17804107, 0.06923712, 0.11467291],\n",
       "        [0.07111957, 0.11434816, 0.01612724, 0.06756573],\n",
       "        [0.06008054, 0.10007597, 0.00382696, 0.05460329],\n",
       "        [0.10010996, 0.1530406 , 0.04680717, 0.09665181]]),\n",
       " array([[0.16341611, 0.13926485, 0.08253848, 0.17770537],\n",
       "        [0.15800572, 0.19858751, 0.14253159, 0.23945205],\n",
       "        [0.16422831, 0.21316464, 0.15417394, 0.2549047 ],\n",
       "        [0.15403768, 0.14554889, 0.09218564, 0.18255487],\n",
       "        [0.15609701, 0.07152962, 0.02040638, 0.10636492],\n",
       "        [0.15225769, 0.05418453, 0.00540283, 0.08858406],\n",
       "        [0.16061672, 0.11521838, 0.06040859, 0.15251566]]),\n",
       " array([[0.14203722, 0.14396536, 0.13082188, 0.09108279],\n",
       "        [0.17427378, 0.18493184, 0.12141502, 0.136282  ],\n",
       "        [0.18367438, 0.19567282, 0.1274732 , 0.14714367],\n",
       "        [0.14231772, 0.14609838, 0.12153355, 0.09687009],\n",
       "        [0.10279453, 0.09619028, 0.12532413, 0.04060045],\n",
       "        [0.09291971, 0.0843443 , 0.12119402, 0.02742617],\n",
       "        [0.1280993 , 0.12702095, 0.12883427, 0.07298579]]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = input_embedding @ wq\n",
    "k = input_embedding @ wk\n",
    "v = input_embedding @ wv\n",
    "\n",
    "q,k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "591734ce-5bb0-4973-b9be-a727bd5cb928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    ex = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return(ex/np.sum(ex, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b7b52fb2-4be2-4d19-8e24-612b3efcb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qk.shape : (7, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.03423574, 0.04448057, 0.04735229, 0.03482069, 0.02191223,\n",
       "        0.01869911, 0.02985458],\n",
       "       [0.04585538, 0.05991315, 0.06380421, 0.04671772, 0.02904229,\n",
       "        0.02466989, 0.03987747],\n",
       "       [0.04895569, 0.06401215, 0.06817167, 0.04988756, 0.03096321,\n",
       "        0.0262865 , 0.04255855],\n",
       "       [0.03508721, 0.04566608, 0.04861999, 0.03570521, 0.02238414,\n",
       "        0.01907461, 0.03057099],\n",
       "       [0.02044234, 0.02621141, 0.02788203, 0.02070975, 0.01339828,\n",
       "        0.01154839, 0.01793853],\n",
       "       [0.01688718, 0.02149362, 0.02285412, 0.01707075, 0.01121138,\n",
       "        0.00971398, 0.01486978],\n",
       "       [0.02935585, 0.03801244, 0.04045859, 0.0298274 , 0.01890467,\n",
       "        0.01617482, 0.02564045]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = (q@k.T)/(d_model)**0.5\n",
    "\n",
    "print(f\"qk.shape : {qk.shape}\")\n",
    "qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7d4ccdb8-84ba-436a-8e27-148f0cb842bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14301958, 0.14449232, 0.14490786, 0.14310327, 0.14126789,\n",
       "        0.14081471, 0.14239436],\n",
       "       [0.14307103, 0.14509649, 0.14566217, 0.14319446, 0.14068567,\n",
       "        0.14007188, 0.14221831],\n",
       "       [0.1430844 , 0.14525505, 0.1458605 , 0.1432178 , 0.14053298,\n",
       "        0.13987728, 0.14217199],\n",
       "       [0.14302337, 0.14454443, 0.14497203, 0.14311179, 0.14121803,\n",
       "        0.14075144, 0.14237891],\n",
       "       [0.14295627, 0.14378338, 0.14402379, 0.1429945 , 0.14195282,\n",
       "        0.14169046, 0.14259878],\n",
       "       [0.14293958, 0.14359954, 0.14379504, 0.14296582, 0.14213058,\n",
       "        0.14191792, 0.14265151],\n",
       "       [0.14299747, 0.14424072, 0.14459398, 0.14306492, 0.14151076,\n",
       "        0.14112499, 0.14246716]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = softmax(qk)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9457292b-2aad-4d13-ade3-031f844e3d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores.shape : (7, 7)\n",
      "\n",
      "output.shape : (7, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.13832397, 0.14012537, 0.1252328 , 0.08789334],\n",
       "       [0.13843667, 0.1402644 , 0.12523444, 0.08804333],\n",
       "       [0.13846624, 0.14030088, 0.12523488, 0.08808268],\n",
       "       [0.1383336 , 0.14013725, 0.12523293, 0.08790617],\n",
       "       [0.13819153, 0.13996198, 0.12523083, 0.08771708],\n",
       "       [0.13815719, 0.13991961, 0.12523032, 0.08767138],\n",
       "       [0.13827699, 0.14006741, 0.1252321 , 0.08783082]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output = scores @ v\n",
    "\n",
    "print(f\"scores.shape : {scores.shape}\")\n",
    "print()\n",
    "print(f\"output.shape : {attn_output.shape}\")\n",
    "attn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94032d8-c50f-4980-aea1-145f221b5349",
   "metadata": {},
   "source": [
    "### Add and Norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ee473c8e-e531-4984-97c5-f6d0b10009a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17577798,  1.2351968 ,  0.19843219,  1.14775919],\n",
       "       [ 0.99550951,  1.15581385,  0.14104264,  1.17461094],\n",
       "       [ 1.10787516,  1.21090815,  0.14729199,  1.18487367],\n",
       "       [ 0.36269787,  1.1609212 ,  0.17341092,  1.10579665],\n",
       "       [-0.58818674,  1.19163773,  0.20841467,  1.1160401 ],\n",
       "       [-0.7595818 ,  1.15261926,  0.20442396,  1.12305782],\n",
       "       [-0.09553151,  1.21678555,  0.20516349,  1.13745481]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(x):\n",
    "    eps = 1e-6\n",
    "    avg = np.mean(x, axis=-1, keepdims=True)\n",
    "    std = np.std(x, axis=-1, keepdims=True)\n",
    "    return (x - avg)/(std+eps)\n",
    "\n",
    "add = attn_output + input_embedding\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "913242b9-78da-48fd-9684-ffe440fd9fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.02049228,  1.08486346, -0.97547215,  0.91110096],\n",
       "        [ 0.30317234,  0.68060205, -1.70863337,  0.72485899],\n",
       "        [ 0.43994389,  0.67223463, -1.72571771,  0.61353918],\n",
       "        [-0.77130081,  1.05016158, -1.20323389,  0.92437312],\n",
       "        [-1.46799378,  0.97347617, -0.3752577 ,  0.86977531],\n",
       "        [-1.51444963,  0.91969673, -0.28731345,  0.88206635],\n",
       "        [-1.24426519,  1.05070511, -0.71841202,  0.9119721 ]]),\n",
       " (7, 4))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_output = norm(add)\n",
    "norm_output, norm_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31fde40-36ac-461b-9594-1bb68cd3f6ab",
   "metadata": {},
   "source": [
    "### FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5cab9f76-3e83-4f9d-b90a-27a0707c01da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 8),\n",
       " array([[4.17022005e-02, 7.20324493e-02, 1.14374817e-05, 3.02332573e-02,\n",
       "         1.46755891e-02, 9.23385948e-03, 1.86260211e-02, 3.45560727e-02],\n",
       "        [3.96767474e-02, 5.38816734e-02, 4.19194514e-02, 6.85219500e-02,\n",
       "         2.04452250e-02, 8.78117436e-02, 2.73875932e-03, 6.70467510e-02],\n",
       "        [4.17304802e-02, 5.58689828e-02, 1.40386939e-02, 1.98101489e-02,\n",
       "         8.00744569e-02, 9.68261576e-02, 3.13424178e-02, 6.92322616e-02],\n",
       "        [8.76389152e-02, 8.94606664e-02, 8.50442114e-03, 3.90547832e-03,\n",
       "         1.69830420e-02, 8.78142503e-02, 9.83468338e-03, 4.21107625e-02]]),\n",
       " (8,),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " (8, 4),\n",
       " array([[0.09578895, 0.05331653, 0.06918771, 0.03155156],\n",
       "        [0.06865009, 0.08346257, 0.00182883, 0.07501443],\n",
       "        [0.09888611, 0.07481657, 0.0280444 , 0.07892793],\n",
       "        [0.0103226 , 0.04478935, 0.09085955, 0.02936141],\n",
       "        [0.02877753, 0.01300286, 0.0019367 , 0.06788355],\n",
       "        [0.02116281, 0.02655467, 0.04915732, 0.00533625],\n",
       "        [0.05741176, 0.01467286, 0.05893055, 0.06997584],\n",
       "        [0.01023344, 0.0414056 , 0.06944002, 0.04141793]]),\n",
       " (4,),\n",
       " array([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 0.1\n",
    "d_ff = 8\n",
    "\n",
    "np.random.seed(1)\n",
    "wx = np.random.rand(d_model, d_ff) * scale\n",
    "bx = np.zeros(d_ff,) \n",
    "wc = np.random.rand(d_ff, d_model) * scale\n",
    "bc = np.zeros(d_model,)\n",
    "\n",
    "wx.shape, wx, bx.shape, bx, wc.shape, wc, bc.shape, bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5658e4fe-5531-48eb-8be7-44879bb6b4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03962806,  0.01195476,  0.03951924,  0.02771819, -0.05543318,\n",
       "          0.0713971 , -0.0376498 ,  0.00830538],\n",
       "        [ 0.03187079,  0.02789698,  0.01071146,  0.02478471, -0.10614328,\n",
       "         -0.03922315, -0.03891304, -0.03165959],\n",
       "        [ 0.02677359,  0.02638489,  0.00917571,  0.0275732 , -0.10756572,\n",
       "         -0.05012466, -0.03801871, -0.03336486],\n",
       "        [ 0.04030158,  0.01649736,  0.0349828 ,  0.02841406, -0.07049814,\n",
       "          0.04976305, -0.04011147, -0.00061975],\n",
       "        [ 0.03797228,  0.00355475,  0.0429196 ,  0.01828523, -0.01691786,\n",
       "          0.1119713 , -0.02788429,  0.02518728],\n",
       "        [ 0.0386483 ,  0.00332362,  0.04200382,  0.01498584, -0.01144833,\n",
       "          0.1164145 , -0.0260196 ,  0.02658237],\n",
       "        [ 0.03974453,  0.00843496,  0.04170098,  0.02370801, -0.03881681,\n",
       "          0.09129795, -0.03384589,  0.016116  ]]),\n",
       " (7, 8))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff1 = norm_output @ wx + bx\n",
    "ff1, ff1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a76b45bb-32d4-484d-80a8-fdbd78b0692e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.03962806, 0.01195476, 0.03951924, 0.02771819, 0.        ,\n",
       "         0.0713971 , 0.        , 0.00830538],\n",
       "        [0.03187079, 0.02789698, 0.01071146, 0.02478471, 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.02677359, 0.02638489, 0.00917571, 0.0275732 , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.04030158, 0.01649736, 0.0349828 , 0.02841406, 0.        ,\n",
       "         0.04976305, 0.        , 0.        ],\n",
       "        [0.03797228, 0.00355475, 0.0429196 , 0.01828523, 0.        ,\n",
       "         0.1119713 , 0.        , 0.02518728],\n",
       "        [0.0386483 , 0.00332362, 0.04200382, 0.01498584, 0.        ,\n",
       "         0.1164145 , 0.        , 0.02658237],\n",
       "        [0.03974453, 0.00843496, 0.04170098, 0.02370801, 0.        ,\n",
       "         0.09129795, 0.        , 0.016116  ]]),\n",
       " (7, 8))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff2 = np.maximum(0,ff1)\n",
    "ff2, ff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4a591169-686b-4ea2-ac9e-097e97ffb535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.01040661, 0.00954859, 0.01047681, 0.00680511],\n",
       "        [0.00628306, 0.00593908, 0.00480841, 0.0046714 ],\n",
       "        [0.00556792, 0.00555111, 0.00466327, 0.0043578 ],\n",
       "        [0.00979874, 0.00873703, 0.00882752, 0.00637006],\n",
       "        [0.01094164, 0.01036757, 0.01275197, 0.00702989],\n",
       "        [0.01097422, 0.01034379, 0.01278815, 0.00694622],\n",
       "        [0.01085157, 0.01009651, 0.01169589, 0.0070289 ]]),\n",
       " (7, 4))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff3 = ff2 @ wc + bc\n",
    "ff3, ff3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75e7c6-7cc5-4f13-91b0-cffd3832106b",
   "metadata": {},
   "source": [
    "### Mask Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "379e0dfc-ca92-4094-a67b-17e28b21c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, '->', array([0.00979874, 0.00873703, 0.00882752, 0.00637006]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_id = tokens.index('[MASK]')\n",
    "mask_vector =  ff3[mask]\n",
    "a = '->'\n",
    "\n",
    "mask_id, a, mask_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0639cda6-0d87-4f9f-9137-d1ec7c7af5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08324426, 0.02123391, 0.0181825 , 0.01834045])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix[mask_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8f5b6e67-592e-4bc1-a307-916a7f90a2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00222516, 0.0008922 , 0.00184367, 0.00127855, 0.00132342,\n",
       "       0.00121268, 0.00163674])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = embed_matrix @ mask_vector\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9e4ff3a9-b2a8-4066-ad4e-d89f0299c33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_id_predicted = np.argmax(scores)\n",
    "mask_id_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0244434e-fbf6-4591-930d-5c57caf249f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token = idx2token[mask_id_predicted]\n",
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2796037f-7b47-4c47-9dca-e740ed744783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_y_origin = playing\n",
      "d_origin = 3\n",
      "mask_y_pred = [CLS]\n",
      "d_origin = 0\n"
     ]
    }
   ],
   "source": [
    "print(f'mask_y_origin = {idx2token[3]}')\n",
    "print(f'd_origin = {token2idx['playing']}')\n",
    "print(f'mask_y_pred = {idx2token[mask_id_predicted]}')\n",
    "print(f'd_origin = {token2idx[predicted_token]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bfb3f-1b34-4dcd-b1ab-042ab4fac18a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b20ce665-d188-4b95-95e0-98ac7da8f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14296255, 0.14277212, 0.14290802, 0.14282728, 0.14283369,\n",
       "       0.14281788, 0.14287845])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = scores\n",
    "probs = softmax(logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "43130a35-3fc3-4318-bfef-87516ab097ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9461191762252408"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = token2idx['playing']\n",
    "loss = -np.log(probs[label])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd385cc-b2a4-4310-9361-44b5c075c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "d_model = 32\n",
    "num_heads = 2\n",
    "d_ff = 64\n",
    "len_ids = len(token_ids)\n",
    "lr = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "embed_matrix = np.random.randn(vocab_size, embed_dim) * 0.01\n",
    "position_embeddings = np.random.randn(seq_len, embed_dim) * 0.01\n",
    "\n",
    "Wq = np.random.randn(embed_dim, embed_dim) * 0.01\n",
    "Wk = np.random.randn(embed_dim, embed_dim) * 0.01\n",
    "Wv = np.random.randn(embed_dim, embed_dim) * 0.01\n",
    "Wo = np.random.randn(embed_dim, embed_dim) * 0.01\n",
    "\n",
    "W1 = np.random.randn(embed_dim, ffn_dim) * 0.01\n",
    "W2 = np.random.randn(ffn_dim, embed_dim) * 0.01\n",
    "\n",
    "vocab_weights = np.random.randn(embed_dim, vocab_size) * 0.01\n",
    "\n",
    "input_ids = token_ids\n",
    "true_label = 'playing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651a192-2f83-4a2e-9c54-1d7c3449f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.1\n",
    "d_model = 4\n",
    "\n",
    "np.random.seed(42)\n",
    "embed_matrix = np.random.rand(len(vocab), d_model) * scale\n",
    "embed_matrix + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712f593-0157-4fe3-b159-659b03a43f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # word embedding\n",
    "    embed_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "090cdd4d-df3b-4d8c-b25f-f045e7805790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Loss: 2.2220\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 20/1000, Loss: 2.1333\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 30/1000, Loss: 2.0457\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 40/1000, Loss: 1.9591\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 50/1000, Loss: 1.8738\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 60/1000, Loss: 1.7898\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 70/1000, Loss: 1.7072\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 80/1000, Loss: 1.6260\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 90/1000, Loss: 1.5465\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 100/1000, Loss: 1.4686\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 110/1000, Loss: 1.3925\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 120/1000, Loss: 1.3182\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 130/1000, Loss: 1.2459\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 140/1000, Loss: 1.1757\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 150/1000, Loss: 1.1076\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 160/1000, Loss: 1.0417\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 170/1000, Loss: 0.9781\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 180/1000, Loss: 0.9169\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 190/1000, Loss: 0.8581\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 200/1000, Loss: 0.8017\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 210/1000, Loss: 0.7477\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 220/1000, Loss: 0.6963\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 230/1000, Loss: 0.6474\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 240/1000, Loss: 0.6009\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 250/1000, Loss: 0.5570\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 260/1000, Loss: 0.5155\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 270/1000, Loss: 0.4764\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 280/1000, Loss: 0.4396\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 290/1000, Loss: 0.4052\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 300/1000, Loss: 0.3729\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 310/1000, Loss: 0.3429\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 320/1000, Loss: 0.3148\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 330/1000, Loss: 0.2888\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 340/1000, Loss: 0.2646\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 350/1000, Loss: 0.2422\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 360/1000, Loss: 0.2215\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 370/1000, Loss: 0.2024\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 380/1000, Loss: 0.1848\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 390/1000, Loss: 0.1686\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 400/1000, Loss: 0.1537\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 410/1000, Loss: 0.1401\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 420/1000, Loss: 0.1276\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 430/1000, Loss: 0.1161\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 440/1000, Loss: 0.1056\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 450/1000, Loss: 0.0960\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 460/1000, Loss: 0.0873\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 470/1000, Loss: 0.0793\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 480/1000, Loss: 0.0720\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 490/1000, Loss: 0.0654\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 500/1000, Loss: 0.0593\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 510/1000, Loss: 0.0538\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 520/1000, Loss: 0.0488\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 530/1000, Loss: 0.0443\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 540/1000, Loss: 0.0401\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 550/1000, Loss: 0.0364\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 560/1000, Loss: 0.0330\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 570/1000, Loss: 0.0299\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 580/1000, Loss: 0.0271\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 590/1000, Loss: 0.0245\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 600/1000, Loss: 0.0222\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 610/1000, Loss: 0.0201\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 620/1000, Loss: 0.0182\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 630/1000, Loss: 0.0165\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 640/1000, Loss: 0.0149\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 650/1000, Loss: 0.0135\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 660/1000, Loss: 0.0123\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 670/1000, Loss: 0.0111\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 680/1000, Loss: 0.0100\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 690/1000, Loss: 0.0091\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 700/1000, Loss: 0.0082\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 710/1000, Loss: 0.0074\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 720/1000, Loss: 0.0067\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 730/1000, Loss: 0.0061\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 740/1000, Loss: 0.0055\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 750/1000, Loss: 0.0050\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 760/1000, Loss: 0.0045\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 770/1000, Loss: 0.0041\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 780/1000, Loss: 0.0037\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 790/1000, Loss: 0.0034\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 800/1000, Loss: 0.0030\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 810/1000, Loss: 0.0027\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 820/1000, Loss: 0.0025\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 830/1000, Loss: 0.0022\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 840/1000, Loss: 0.0020\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 850/1000, Loss: 0.0018\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 860/1000, Loss: 0.0017\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 870/1000, Loss: 0.0015\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 880/1000, Loss: 0.0014\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 890/1000, Loss: 0.0012\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 900/1000, Loss: 0.0011\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 910/1000, Loss: 0.0010\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 920/1000, Loss: 0.0009\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 930/1000, Loss: 0.0008\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 940/1000, Loss: 0.0007\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 950/1000, Loss: 0.0007\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 960/1000, Loss: 0.0006\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 970/1000, Loss: 0.0006\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 980/1000, Loss: 0.0005\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 990/1000, Loss: 0.0005\n",
      "Current prediction: playing, Target: playing\n",
      "Epoch 1000/1000, Loss: 0.0004\n",
      "Current prediction: playing, Target: playing\n",
      "\n",
      "Final prediction: playing\n",
      "Target token: playing\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Your existing functions\n",
    "def data(corpus):    \n",
    "    vocab = corpus.split()    \n",
    "    vocab.insert(0, '[CLS]')    \n",
    "    vocab.extend(['[SEP]', '[MASK]'])    \n",
    "    return vocab\n",
    "\n",
    "def tokennizer(vocab):    \n",
    "    token2idx = {}    \n",
    "    idx2token = {}    \n",
    "    for idx, token in enumerate(vocab):        \n",
    "        token2idx[token] = idx        \n",
    "        idx2token[idx] = token    \n",
    "    return token2idx, idx2token\n",
    "\n",
    "def masking(corpus):    \n",
    "    tokens = corpus.split()    \n",
    "    tokens.insert(0, '[CLS]')    \n",
    "    tokens.extend(['[SEP]', '[MASK]'])    \n",
    "    labels = 'playing'    \n",
    "    tokens[tokens.index(labels)] = '[MASK]'    \n",
    "    return tokens\n",
    "\n",
    "def token_ids(tokens, token2idx):    \n",
    "    token_ids = []    \n",
    "    for token in tokens:        \n",
    "        token_ids.append(token2idx[token])    \n",
    "    return token_ids, len(token_ids)\n",
    "\n",
    "def embedding(scale, d_model, vocab_size):    \n",
    "    np.random.seed(42)    \n",
    "    embed_matrix = np.random.rand(vocab_size, d_model) * scale    \n",
    "    return embed_matrix\n",
    "\n",
    "def position_embedding(seq_len, d_model, vocab_size):    \n",
    "    pos = np.arange(seq_len).reshape(seq_len,1)    \n",
    "    i = np.arange(d_model)   \n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))    \n",
    "    angle_rads = pos * angle_rates    \n",
    "    pe = np.zeros((seq_len, d_model))\n",
    "    pe[:, 0::2] = np.sin(angle_rads[:, 0::2])    \n",
    "    pe[:, 1::2] = np.cos(angle_rads[:, 1::2])            \n",
    "    return pe\n",
    "\n",
    "def embedding_output(embed_matrix, position_embedding):    \n",
    "    return embed_matrix + position_embedding\n",
    "\n",
    "def attention_weights(d_model):    \n",
    "    Wq = np.random.randn(d_model, d_model) * 0.01    \n",
    "    Wk = np.random.randn(d_model, d_model) * 0.01    \n",
    "    Wv = np.random.randn(d_model, d_model) * 0.01    \n",
    "    return Wq, Wk, Wv\n",
    "\n",
    "def attention_output(x, Wq, Wk, Wv):    \n",
    "    Q = x @ Wq    \n",
    "    K = x @ Wk    \n",
    "    V = x @ Wv    \n",
    "    d_k = Q.shape[-1]    \n",
    "    scaled = np.matmul(Q, K.transpose()) / np.sqrt(d_k)    \n",
    "    softmax = np.exp(scaled) / np.sum(np.exp(scaled), axis=-1, keepdims=True)    \n",
    "    return np.matmul(softmax, V)\n",
    "\n",
    "def add_and_norm(x, attention_output):    \n",
    "    eps = 1e1    \n",
    "    avg = np.mean(x, axis=-1, keepdims=True)    \n",
    "    std = np.std(x, axis=-1, keepdims=True)    \n",
    "    norm = (x - avg) / (std + eps)    \n",
    "    norm_output = attention_output + norm    \n",
    "    return norm_output    \n",
    "\n",
    "def ffn_weights(d_model, d_ff):    \n",
    "    W1 = np.random.randn(d_model, d_ff) * 0.01    \n",
    "    W2 = np.random.randn(d_ff, d_model) * 0.01    \n",
    "    return W1, W2\n",
    "\n",
    "def ffn_output(norm_output, W1, W2):    \n",
    "    ffn_output = np.matmul(norm_output, W1)    \n",
    "    relu = np.maximum(0, ffn_output)    \n",
    "    ffn_output = np.matmul(relu, W2)    \n",
    "    return ffn_output\n",
    "\n",
    "# New functions for the training loop\n",
    "\n",
    "def initialize_model(d_model, d_ff, vocab_size):\n",
    "    \"\"\"Initialize all model weights\"\"\"\n",
    "    scale = 0.01\n",
    "    Wq, Wk, Wv = attention_weights(d_model)\n",
    "    W1, W2 = ffn_weights(d_model, d_ff)\n",
    "    embed_matrix = embedding(scale, d_model, vocab_size)\n",
    "    \n",
    "    # Output layer for masked language modeling\n",
    "    W_output = np.random.randn(d_model, vocab_size) * 0.01\n",
    "    b_output = np.zeros(vocab_size)\n",
    "    \n",
    "    return {\n",
    "        'Wq': Wq, 'Wk': Wk, 'Wv': Wv,\n",
    "        'W1': W1, 'W2': W2,\n",
    "        'embed_matrix': embed_matrix,\n",
    "        'W_output': W_output,\n",
    "        'b_output': b_output\n",
    "    }\n",
    "\n",
    "def forward_pass(token_ids_input, seq_len, model_params, d_model, vocab_size):\n",
    "    \"\"\"Forward pass through the model\"\"\"\n",
    "    # Convert token IDs to one-hot matrix for embedding lookup\n",
    "    input_matrix = np.zeros((seq_len, len(model_params['embed_matrix'])))\n",
    "    for i, idx in enumerate(token_ids_input):\n",
    "        input_matrix[i, idx] = 1\n",
    "    \n",
    "    # Get token embeddings\n",
    "    token_embeds = input_matrix @ model_params['embed_matrix']\n",
    "    \n",
    "    # Add positional encoding\n",
    "    pos_enc = position_embedding(seq_len, d_model, vocab_size)\n",
    "    x = embedding_output(token_embeds, pos_enc)\n",
    "    \n",
    "    # Transformer layer\n",
    "    attn_out = attention_output(x, model_params['Wq'], model_params['Wk'], model_params['Wv'])\n",
    "    norm1 = add_and_norm(x, attn_out)\n",
    "    ffn_out = ffn_output(norm1, model_params['W1'], model_params['W2'])\n",
    "    encoder_output = add_and_norm(norm1, ffn_out)\n",
    "    \n",
    "    # Prediction layer\n",
    "    logits = encoder_output @ model_params['W_output'] + model_params['b_output']\n",
    "    \n",
    "    # Softmax for probabilities\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n",
    "    \n",
    "    return probs, encoder_output\n",
    "\n",
    "def compute_loss(probs, target_idx, mask_position):\n",
    "    \"\"\"Compute cross-entropy loss for masked token prediction\"\"\"\n",
    "    # Only calculate loss for the masked position\n",
    "    mask_probs = probs[mask_position]\n",
    "    loss = -np.log(mask_probs[target_idx] + 1e-10)  # Add small epsilon to avoid log(0)\n",
    "    return loss\n",
    "\n",
    "def backward_pass(loss, probs, target_idx, encoder_output, model_params, \n",
    "                 token_ids_input, mask_position, learning_rate=0.01):\n",
    "    \"\"\"Simple backward pass with parameter updates\"\"\"\n",
    "    # Initialize gradients\n",
    "    d_W_output = np.zeros_like(model_params['W_output'])\n",
    "    d_b_output = np.zeros_like(model_params['b_output'])\n",
    "    \n",
    "    # Gradient for output layer (only at mask position)\n",
    "    d_probs = np.zeros_like(probs[mask_position])\n",
    "    d_probs[target_idx] = -1.0 / (probs[mask_position, target_idx] + 1e-10)\n",
    "    \n",
    "    # Softmax gradient\n",
    "    d_logits = probs[mask_position] * d_probs\n",
    "    \n",
    "    # Output layer gradients\n",
    "    d_W_output += np.outer(encoder_output[mask_position], d_logits)\n",
    "    d_b_output += d_logits\n",
    "    \n",
    "    # Update parameters (simplified, real backprop would be more complex)\n",
    "    model_params['W_output'] -= learning_rate * d_W_output\n",
    "    model_params['b_output'] -= learning_rate * d_b_output\n",
    "    \n",
    "    # For a full implementation, we'd need to backprop through the entire network\n",
    "    # This is a simplified version that only updates the output layer\n",
    "    \n",
    "    return model_params\n",
    "\n",
    "def train_model(corpus, masked_token, n_epochs=100):\n",
    "    \"\"\"Train the model for masked language modeling\"\"\"\n",
    "    # Hyperparameters\n",
    "    d_model = 16  # Embedding dimension\n",
    "    d_ff = 64     # Feed-forward network dimension\n",
    "    \n",
    "    # Process the corpus\n",
    "    vocab = data(corpus)\n",
    "    token2idx, idx2token = tokennizer(vocab)\n",
    "    tokens = masking(corpus)\n",
    "    token_ids_input, seq_len = token_ids(tokens, token2idx)\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    # Find mask position and target token index\n",
    "    mask_position = tokens.index('[MASK]')\n",
    "    target_idx = token2idx[masked_token]\n",
    "    \n",
    "    # Initialize model\n",
    "    model_params = initialize_model(d_model, d_ff, vocab_size)\n",
    "    \n",
    "    # Training loop\n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # Forward pass\n",
    "        probs, encoder_output = forward_pass(token_ids_input, seq_len, model_params, d_model, vocab_size)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = compute_loss(probs, target_idx, mask_position)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # Backward pass and update parameters\n",
    "        model_params = backward_pass(loss, probs, target_idx, encoder_output, \n",
    "                                    model_params, token_ids_input, mask_position)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss:.4f}\")\n",
    "            \n",
    "            # Show prediction\n",
    "            predicted_idx = np.argmax(probs[mask_position])\n",
    "            print(f\"Current prediction: {idx2token[predicted_idx]}, Target: {idx2token[target_idx]}\")\n",
    "    \n",
    "    # Final prediction\n",
    "    final_probs, _ = forward_pass(token_ids_input, seq_len, model_params, d_model, vocab_size)\n",
    "    predicted_idx = np.argmax(final_probs[mask_position])\n",
    "    print(f\"\\nFinal prediction: {idx2token[predicted_idx]}\")\n",
    "    print(f\"Target token: {idx2token[target_idx]}\")\n",
    "    \n",
    "    return model_params, losses\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    corpus = \"the cat is playing with the ball\"\n",
    "    masked_token = \"playing\"  # This is the token we want to predict\n",
    "    \n",
    "    model_params, losses = train_model(corpus, masked_token, n_epochs=1000)\n",
    "    \n",
    "    # Plot loss curve\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(losses)\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    except ImportError:\n",
    "        print(\"matplotlib not available for plotting losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d26cb1-cfe0-42f0-9cc5-72e8d0a8ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8\n",
      "Input sequence: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Input IDs: [7, 6, 0, 2, 3, 5, 7, 4, 1]\n",
      "Target IDs: [6, 0, 2, 3, 5, 7, 4, 1, 7]\n",
      "\n",
      "Training model...\n",
      "Epoch 10/1000, Loss: 2.0794\n",
      "Epoch 20/1000, Loss: 2.0794\n",
      "Epoch 30/1000, Loss: 2.0794\n",
      "Epoch 40/1000, Loss: 2.0794\n",
      "Epoch 50/1000, Loss: 2.0794\n",
      "Epoch 60/1000, Loss: 2.0794\n",
      "Epoch 70/1000, Loss: 2.0794\n",
      "Epoch 80/1000, Loss: 2.0794\n",
      "Epoch 90/1000, Loss: 2.0794\n",
      "Epoch 100/1000, Loss: 2.0794\n",
      "Epoch 110/1000, Loss: 2.0794\n",
      "Epoch 120/1000, Loss: 2.0794\n",
      "Epoch 130/1000, Loss: 2.0794\n",
      "Epoch 140/1000, Loss: 2.0794\n",
      "Epoch 150/1000, Loss: 2.0794\n",
      "Epoch 160/1000, Loss: 2.0794\n",
      "Epoch 170/1000, Loss: 2.0794\n",
      "Epoch 180/1000, Loss: 2.0794\n",
      "Epoch 190/1000, Loss: 2.0794\n",
      "Epoch 200/1000, Loss: 2.0794\n",
      "Epoch 210/1000, Loss: 2.0794\n",
      "Epoch 220/1000, Loss: 2.0794\n",
      "Epoch 230/1000, Loss: 2.0794\n",
      "Epoch 240/1000, Loss: 2.0794\n",
      "Epoch 250/1000, Loss: 2.0794\n",
      "Epoch 260/1000, Loss: 2.0794\n",
      "Epoch 270/1000, Loss: 2.0794\n",
      "Epoch 280/1000, Loss: 2.0794\n",
      "Epoch 290/1000, Loss: 2.0794\n",
      "Epoch 300/1000, Loss: 2.0794\n",
      "Epoch 310/1000, Loss: 2.0794\n",
      "Epoch 320/1000, Loss: 2.0794\n",
      "Epoch 330/1000, Loss: 2.0794\n",
      "Epoch 340/1000, Loss: 2.0794\n",
      "Epoch 350/1000, Loss: 2.0794\n",
      "Epoch 360/1000, Loss: 2.0794\n",
      "Epoch 370/1000, Loss: 2.0794\n",
      "Epoch 380/1000, Loss: 2.0794\n",
      "Epoch 390/1000, Loss: 2.0794\n",
      "Epoch 400/1000, Loss: 2.0794\n",
      "Epoch 410/1000, Loss: 2.0794\n",
      "Epoch 420/1000, Loss: 2.0794\n",
      "Epoch 430/1000, Loss: 2.0794\n",
      "Epoch 440/1000, Loss: 2.0794\n",
      "Epoch 450/1000, Loss: 2.0794\n",
      "Epoch 460/1000, Loss: 2.0794\n",
      "Epoch 470/1000, Loss: 2.0794\n",
      "Epoch 480/1000, Loss: 2.0794\n",
      "Epoch 490/1000, Loss: 2.0794\n",
      "Epoch 500/1000, Loss: 2.0794\n",
      "Epoch 510/1000, Loss: 2.0794\n",
      "Epoch 520/1000, Loss: 2.0794\n",
      "Epoch 530/1000, Loss: 2.0794\n",
      "Epoch 540/1000, Loss: 2.0794\n",
      "Epoch 550/1000, Loss: 2.0794\n",
      "Epoch 560/1000, Loss: 2.0794\n",
      "Epoch 570/1000, Loss: 2.0794\n",
      "Epoch 580/1000, Loss: 2.0794\n",
      "Epoch 590/1000, Loss: 2.0794\n",
      "Epoch 600/1000, Loss: 2.0794\n",
      "Epoch 610/1000, Loss: 2.0794\n",
      "Epoch 620/1000, Loss: 2.0794\n",
      "Epoch 630/1000, Loss: 2.0794\n",
      "Epoch 640/1000, Loss: 2.0794\n",
      "Epoch 650/1000, Loss: 2.0794\n",
      "Epoch 660/1000, Loss: 2.0794\n",
      "Epoch 670/1000, Loss: 2.0794\n",
      "Epoch 680/1000, Loss: 2.0794\n",
      "Epoch 690/1000, Loss: 2.0794\n",
      "Epoch 700/1000, Loss: 2.0794\n",
      "Epoch 710/1000, Loss: 2.0794\n",
      "Epoch 720/1000, Loss: 2.0794\n",
      "Epoch 730/1000, Loss: 2.0794\n",
      "Epoch 740/1000, Loss: 2.0794\n",
      "Epoch 750/1000, Loss: 2.0794\n",
      "Epoch 760/1000, Loss: 2.0794\n",
      "Epoch 770/1000, Loss: 2.0794\n",
      "Epoch 780/1000, Loss: 2.0794\n",
      "Epoch 790/1000, Loss: 2.0794\n",
      "Epoch 800/1000, Loss: 2.0794\n",
      "Epoch 810/1000, Loss: 2.0794\n",
      "Epoch 820/1000, Loss: 2.0794\n",
      "Epoch 830/1000, Loss: 2.0794\n",
      "Epoch 840/1000, Loss: 2.0794\n",
      "Epoch 850/1000, Loss: 2.0794\n",
      "Epoch 860/1000, Loss: 2.0794\n",
      "Epoch 870/1000, Loss: 2.0794\n",
      "Epoch 880/1000, Loss: 2.0794\n",
      "Epoch 890/1000, Loss: 2.0794\n",
      "Epoch 900/1000, Loss: 2.0794\n",
      "Epoch 910/1000, Loss: 2.0794\n",
      "Epoch 920/1000, Loss: 2.0794\n",
      "Epoch 930/1000, Loss: 2.0794\n",
      "Epoch 940/1000, Loss: 2.0794\n",
      "Epoch 950/1000, Loss: 2.0794\n",
      "Epoch 960/1000, Loss: 2.0794\n",
      "Epoch 970/1000, Loss: 2.0794\n",
      "Epoch 980/1000, Loss: 2.0794\n",
      "Epoch 990/1000, Loss: 2.0794\n",
      "Epoch 1000/1000, Loss: 2.0794\n",
      "Final loss: 2.0794\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ========== Preprocessing Functions ==========\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Split text into individual tokens (words/subwords).\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to tokenize\n",
    "        \n",
    "    Returns:\n",
    "        list: List of tokens\n",
    "    \"\"\"\n",
    "    return text.split()\n",
    "\n",
    "def get_vocab(text):\n",
    "    \"\"\"Create vocabulary from text by extracting unique tokens.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to build vocabulary from\n",
    "        \n",
    "    Returns:\n",
    "        list: Sorted list of unique tokens\n",
    "    \"\"\"\n",
    "    tokens = tokenize(text)\n",
    "    vocab = sorted(set(tokens))\n",
    "    return vocab\n",
    "\n",
    "def get_token_ids(vocab, tokens):\n",
    "    \"\"\"Convert tokens to their corresponding vocabulary indices.\n",
    "    \n",
    "    Args:\n",
    "        vocab (list): Vocabulary list\n",
    "        tokens (list): List of tokens to convert\n",
    "        \n",
    "    Returns:\n",
    "        list: List of token indices\n",
    "    \"\"\"\n",
    "    token_ids = [vocab.index(token) for token in tokens]\n",
    "    return token_ids\n",
    "\n",
    "# ========== Embedding Functions ==========\n",
    "\n",
    "def get_embed_matrix(vocab_size, embed_dim, scale=0.01):\n",
    "    \"\"\"Initialize embedding matrix for vocabulary.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Size of vocabulary\n",
    "        embed_dim (int): Dimension of embeddings\n",
    "        scale (float): Scale for random initialization\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Embedding matrix of shape (vocab_size, embed_dim)\n",
    "    \"\"\"\n",
    "    return np.random.randn(vocab_size, embed_dim) * scale\n",
    "    \n",
    "def get_position_embeddings(seq_len, embed_dim, scale=0.01):\n",
    "    \"\"\"Initialize position embeddings for sequence positions.\n",
    "    \n",
    "    Args:\n",
    "        seq_len (int): Maximum sequence length\n",
    "        embed_dim (int): Dimension of embeddings\n",
    "        scale (float): Scale for random initialization\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Position embedding matrix of shape (seq_len, embed_dim)\n",
    "    \"\"\"\n",
    "    # A more sophisticated implementation would use sine/cosine position embeddings\n",
    "    return np.random.randn(seq_len, embed_dim) * scale\n",
    "\n",
    "# ========== Weight Initialization Functions ==========\n",
    "\n",
    "def get_attention_weights(embed_dim, scale=0.01):\n",
    "    \"\"\"Initialize weights for attention mechanism (Q, K, V, O).\n",
    "    \n",
    "    Args:\n",
    "        embed_dim (int): Dimension of embeddings\n",
    "        scale (float): Scale for random initialization\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Query, Key, Value, and Output projection weights\n",
    "    \"\"\"\n",
    "    Wq = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    Wk = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    Wv = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    Wo = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    return Wq, Wk, Wv, Wo\n",
    "\n",
    "def get_ffn_weights(embed_dim, ffn_dim, scale=0.01):\n",
    "    \"\"\"Initialize weights for feed-forward network.\n",
    "    \n",
    "    Args:\n",
    "        embed_dim (int): Dimension of embeddings\n",
    "        ffn_dim (int): Hidden dimension of feed-forward network\n",
    "        scale (float): Scale for random initialization\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Input and output projection weights\n",
    "    \"\"\"\n",
    "    W1 = np.random.randn(embed_dim, ffn_dim) * scale\n",
    "    W2 = np.random.randn(ffn_dim, embed_dim) * scale\n",
    "    return W1, W2\n",
    "\n",
    "def get_output_weights(embed_dim, vocab_size, scale=0.01):\n",
    "    \"\"\"Initialize weights for output projection to vocabulary space.\n",
    "    \n",
    "    Args:\n",
    "        embed_dim (int): Dimension of embeddings\n",
    "        vocab_size (int): Size of vocabulary\n",
    "        scale (float): Scale for random initialization\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Output projection weights\n",
    "    \"\"\"\n",
    "    return np.random.randn(embed_dim, vocab_size) * scale\n",
    "\n",
    "# ========== Attention Mechanisms ==========\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): Input array\n",
    "        axis (int, optional): Axis along which to compute softmax\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Softmax output with same shape as input\n",
    "    \"\"\"\n",
    "    # Numerically stable softmax\n",
    "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"Compute scaled dot-product attention.\n",
    "    \n",
    "    Args:\n",
    "        Q (np.ndarray): Query tensor\n",
    "        K (np.ndarray): Key tensor\n",
    "        V (np.ndarray): Value tensor\n",
    "        mask (np.ndarray, optional): Optional attention mask\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Attention output and attention weights\n",
    "    \"\"\"\n",
    "    # Get dimensionality of key vectors for scaling\n",
    "    d_k = K.shape[-1]\n",
    "    \n",
    "    # Compute attention scores\n",
    "    attention_scores = np.matmul(Q, K.T) / np.sqrt(d_k)\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        attention_scores = attention_scores + (mask * -1e9)\n",
    "    \n",
    "    # Apply softmax to get attention weights\n",
    "    attention_weights = softmax(attention_scores, axis=-1)\n",
    "    \n",
    "    # Apply attention weights to values\n",
    "    output = np.matmul(attention_weights, V)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "def multi_head_attention(Q, K, V, num_heads):\n",
    "    \"\"\"Perform multi-head attention.\n",
    "    \n",
    "    Args:\n",
    "        Q (np.ndarray): Query tensor\n",
    "        K (np.ndarray): Key tensor\n",
    "        V (np.ndarray): Value tensor\n",
    "        num_heads (int): Number of attention heads\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Concatenated attention output and attention weights\n",
    "    \"\"\"\n",
    "    batch_size = Q.shape[0] if len(Q.shape) > 2 else 1\n",
    "    d_model = Q.shape[-1]\n",
    "    \n",
    "    # Each head dimension\n",
    "    d_head = d_model // num_heads\n",
    "    \n",
    "    # Reshape inputs for multi-head attention\n",
    "    if batch_size > 1:\n",
    "        # Reshape for batched inputs\n",
    "        Q_reshaped = Q.reshape(batch_size, -1, num_heads, d_head).transpose(0, 2, 1, 3)\n",
    "        K_reshaped = K.reshape(batch_size, -1, num_heads, d_head).transpose(0, 2, 1, 3)\n",
    "        V_reshaped = V.reshape(batch_size, -1, num_heads, d_head).transpose(0, 2, 1, 3)\n",
    "    else:\n",
    "        # Reshape for single input\n",
    "        # This implementation assumes Q has shape [seq_len, d_model]\n",
    "        seq_len = Q.shape[0]\n",
    "        Q_reshaped = Q.reshape(seq_len, num_heads, d_head).transpose(1, 0, 2)\n",
    "        K_reshaped = K.reshape(seq_len, num_heads, d_head).transpose(1, 0, 2)\n",
    "        V_reshaped = V.reshape(seq_len, num_heads, d_head).transpose(1, 0, 2)\n",
    "    \n",
    "    # Initialize outputs\n",
    "    outputs = []\n",
    "    attention_weights = []\n",
    "    \n",
    "    # Process each attention head\n",
    "    for i in range(num_heads):\n",
    "        Q_head = Q_reshaped[i] if batch_size == 1 else Q_reshaped[:, i]\n",
    "        K_head = K_reshaped[i] if batch_size == 1 else K_reshaped[:, i]\n",
    "        V_head = V_reshaped[i] if batch_size == 1 else V_reshaped[:, i]\n",
    "        \n",
    "        output, attention = scaled_dot_product_attention(Q_head, K_head, V_head)\n",
    "        outputs.append(output)\n",
    "        attention_weights.append(attention)\n",
    "    \n",
    "    # Concatenate outputs from all heads\n",
    "    if batch_size > 1:\n",
    "        concat_output = np.concatenate(outputs, axis=-1)\n",
    "    else:\n",
    "        concat_output = np.concatenate(outputs, axis=-1)\n",
    "    \n",
    "    # Stack attention weights\n",
    "    stacked_attention_weights = np.stack(attention_weights, axis=0)\n",
    "    \n",
    "    return concat_output, stacked_attention_weights\n",
    "\n",
    "# ========== Feed-Forward Network ==========\n",
    "\n",
    "def feed_forward(x, W1, W2):\n",
    "    \"\"\"Apply feed-forward network transformation.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): Input tensor\n",
    "        W1 (np.ndarray): First weight matrix\n",
    "        W2 (np.ndarray): Second weight matrix\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Output tensor\n",
    "    \"\"\"\n",
    "    # ReLU activation on first layer\n",
    "    hidden = np.maximum(0, np.dot(x, W1))\n",
    "    # Linear projection on second layer\n",
    "    return np.dot(hidden, W2)\n",
    "\n",
    "# ========== Loss Functions ==========\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    \"\"\"Compute cross-entropy loss between logits and labels.\n",
    "    \n",
    "    Args:\n",
    "        logits (np.ndarray): Prediction logits\n",
    "        labels (np.ndarray): One-hot encoded true labels\n",
    "        \n",
    "    Returns:\n",
    "        float: Cross-entropy loss value\n",
    "    \"\"\"\n",
    "    probs = softmax(logits, axis=-1)\n",
    "    # Add small epsilon to avoid log(0)\n",
    "    eps = 1e-10\n",
    "    log_probs = np.log(probs + eps)\n",
    "    loss = -np.mean(np.sum(labels * log_probs, axis=-1))\n",
    "    return loss\n",
    "\n",
    "# ========== Training Function ==========\n",
    "\n",
    "def train_transformer(input_ids, target_ids, model_params, hyperparams):\n",
    "    \"\"\"Train transformer model for sequence prediction.\n",
    "    \n",
    "    Args:\n",
    "        input_ids (np.ndarray): Input token indices\n",
    "        target_ids (np.ndarray): Target token indices\n",
    "        model_params (dict): Dictionary containing model parameters\n",
    "        hyperparams (dict): Dictionary containing hyperparameters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated model parameters and training metrics\n",
    "    \"\"\"\n",
    "    # Unpack model parameters\n",
    "    embed_matrix = model_params['embed_matrix']\n",
    "    position_embeddings = model_params['position_embeddings']\n",
    "    Wq, Wk, Wv, Wo = model_params['attention_weights']\n",
    "    W1, W2 = model_params['ffn_weights']\n",
    "    output_weights = model_params['output_weights']\n",
    "    \n",
    "    # Unpack hyperparameters\n",
    "    lr = hyperparams['learning_rate']\n",
    "    num_epochs = hyperparams['num_epochs']\n",
    "    num_heads = hyperparams['num_heads']\n",
    "    \n",
    "    # Convert target_ids to one-hot\n",
    "    vocab_size = embed_matrix.shape[0]\n",
    "    true_labels = np.zeros((len(target_ids), vocab_size))\n",
    "    for i, idx in enumerate(target_ids):\n",
    "        true_labels[i, idx] = 1\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # === Forward Pass ===\n",
    "        \n",
    "        # Embedding lookup\n",
    "        input_embeddings = embed_matrix[input_ids]\n",
    "        \n",
    "        # Add position embeddings\n",
    "        seq_len = len(input_ids)\n",
    "        input_embeddings += position_embeddings[:seq_len]\n",
    "        \n",
    "        # Self-attention\n",
    "        Q = np.dot(input_embeddings, Wq)\n",
    "        K = np.dot(input_embeddings, Wk)\n",
    "        V = np.dot(input_embeddings, Wv)\n",
    "        \n",
    "        # Multi-head attention\n",
    "        attention_output, attention_weights = multi_head_attention(Q, K, V, num_heads)\n",
    "        \n",
    "        # Project attention output\n",
    "        attention_output = np.dot(attention_output, Wo)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_output = feed_forward(attention_output, W1, W2)\n",
    "        \n",
    "        # Final projection to vocabulary space\n",
    "        logits = np.dot(ffn_output, output_weights)\n",
    "        \n",
    "        # Compute probabilities\n",
    "        probs = softmax(logits, axis=-1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = cross_entropy_loss(logits, true_labels)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # === Backward Pass (Simplified Gradient Descent) ===\n",
    "        \n",
    "        # Note: This is a simplified backward pass implementation\n",
    "        # A real implementation would use automatic differentiation\n",
    "        \n",
    "        # Gradients for output layer\n",
    "        d_logits = probs - true_labels\n",
    "        d_output_weights = np.dot(ffn_output.T, d_logits)\n",
    "        d_ffn_output = np.dot(d_logits, output_weights.T)\n",
    "        \n",
    "        # Gradients for feed-forward network\n",
    "        d_W2 = np.dot(np.maximum(0, np.dot(attention_output, W1)).T, d_ffn_output)\n",
    "        \n",
    "        # Gradient for ReLU activation\n",
    "        d_hidden = np.dot(d_ffn_output, W2.T)\n",
    "        d_hidden[np.dot(attention_output, W1) <= 0] = 0\n",
    "        \n",
    "        d_W1 = np.dot(attention_output.T, d_hidden)\n",
    "        d_attention_output = np.dot(d_hidden, W1.T)\n",
    "        \n",
    "        # Gradients for attention projection\n",
    "        d_Wo = np.dot(attention_output.T, d_attention_output)\n",
    "        d_attention_output_unprojected = np.dot(d_attention_output, Wo.T)\n",
    "        \n",
    "        # Gradients for attention (simplified)\n",
    "        # In a real implementation, you would need to backpropagate through\n",
    "        # the multi-head attention mechanism properly\n",
    "        d_Wv = np.dot(V.T, d_attention_output_unprojected)\n",
    "        d_Wk = np.dot(K.T, d_attention_output_unprojected)\n",
    "        d_Wq = np.dot(Q.T, d_attention_output_unprojected)\n",
    "        \n",
    "        # Update weights\n",
    "        output_weights -= lr * d_output_weights\n",
    "        W2 -= lr * d_W2\n",
    "        W1 -= lr * d_W1\n",
    "        Wo -= lr * d_Wo\n",
    "        Wv -= lr * d_Wv\n",
    "        Wk -= lr * d_Wk\n",
    "        Wq -= lr * d_Wq\n",
    "        \n",
    "        # Embedding gradients (simplified)\n",
    "        d_embeddings = d_attention_output_unprojected\n",
    "        \n",
    "        # In practice, embedding updates would be more complex\n",
    "        # and would handle position embeddings separately\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # Update model parameters\n",
    "    model_params['attention_weights'] = (Wq, Wk, Wv, Wo)\n",
    "    model_params['ffn_weights'] = (W1, W2)\n",
    "    model_params['output_weights'] = output_weights\n",
    "    \n",
    "    return model_params, {'loss': losses}\n",
    "\n",
    "# ========== Example Usage ==========\n",
    "\n",
    "def create_transformer_model(vocab_size, embed_dim, max_seq_len, num_heads, ffn_dim):\n",
    "    \"\"\"Create a transformer model with initialized parameters.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): Size of vocabulary\n",
    "        embed_dim (int): Dimension of embeddings\n",
    "        max_seq_len (int): Maximum sequence length\n",
    "        num_heads (int): Number of attention heads\n",
    "        ffn_dim (int): Hidden dimension of feed-forward network\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing model parameters\n",
    "    \"\"\"\n",
    "    # Initialize model parameters\n",
    "    embed_matrix = get_embed_matrix(vocab_size, embed_dim)\n",
    "    position_embeddings = get_position_embeddings(max_seq_len, embed_dim)\n",
    "    attention_weights = get_attention_weights(embed_dim)\n",
    "    ffn_weights = get_ffn_weights(embed_dim, ffn_dim)\n",
    "    output_weights = get_output_weights(embed_dim, vocab_size)\n",
    "    \n",
    "    # Return as a dictionary\n",
    "    return {\n",
    "        'embed_matrix': embed_matrix,\n",
    "        'position_embeddings': position_embeddings,\n",
    "        'attention_weights': attention_weights,\n",
    "        'ffn_weights': ffn_weights,\n",
    "        'output_weights': output_weights\n",
    "    }\n",
    "\n",
    "def example_usage():\n",
    "    \"\"\"Demonstrate how to use the transformer model.\"\"\"\n",
    "    # Sample text\n",
    "    text = \"the quick brown fox jumps over the lazy dog\"\n",
    "    \n",
    "    # Preprocessing\n",
    "    vocab = get_vocab(text)\n",
    "    tokens = tokenize(text)\n",
    "    input_ids = get_token_ids(vocab, tokens)\n",
    "    target_ids = input_ids[1:] + [input_ids[0]]  # Simple shift for demonstration\n",
    "    \n",
    "    print(f\"Vocabulary size: {len(vocab)}\")\n",
    "    print(f\"Input sequence: {tokens}\")\n",
    "    print(f\"Input IDs: {input_ids}\")\n",
    "    print(f\"Target IDs: {target_ids}\")\n",
    "    \n",
    "    # Model configuration\n",
    "    vocab_size = len(vocab)\n",
    "    embed_dim = 32\n",
    "    max_seq_len = 128\n",
    "    num_heads = 4\n",
    "    ffn_dim = 64\n",
    "    \n",
    "    # Create model\n",
    "    model_params = create_transformer_model(\n",
    "        vocab_size=vocab_size,\n",
    "        embed_dim=embed_dim,\n",
    "        max_seq_len=max_seq_len,\n",
    "        num_heads=num_heads,\n",
    "        ffn_dim=ffn_dim\n",
    "    )\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    hyperparams = {\n",
    "        'learning_rate': 0.001,\n",
    "        'num_epochs': 1000,\n",
    "        'num_heads': num_heads\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining model...\")\n",
    "    model_params, metrics = train_transformer(\n",
    "        input_ids=np.array(input_ids),\n",
    "        target_ids=np.array(target_ids),\n",
    "        model_params=model_params,\n",
    "        hyperparams=hyperparams\n",
    "    )\n",
    "    \n",
    "    print(f\"Final loss: {metrics['loss'][-1]:.4f}\")\n",
    "\n",
    "# Run example if script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c700da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "def vocab(text):\n",
    "    tokens = tokenizer(text)\n",
    "    vocab = sorted(set(tokens))\n",
    "    return vocab\n",
    "\n",
    "def token2idx(vocab, tokens):\n",
    "    token_ids = [vocab.index(token) for token in tokens]\n",
    "    return token_ids\n",
    "\n",
    "def embedding_matrix(vocab_size, embed_dim):\n",
    "    return np.random.randn(vocab_size, embed_dim) * 0.01\n",
    "\n",
    "def positional_encoding(seq_len, embed_dim):\n",
    "    pos = np.arange(seq_len).reshape(seq_len, 1)\n",
    "    i = np.arange(embed_dim)\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n",
    "    angle_rads = pos * angle_rates\n",
    "    pos_encoding = np.zeros((seq_len, embed_dim))\n",
    "    pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    return pos_encoding\n",
    "\n",
    "def attention_weigth(embed_dim, scale=0.01):\n",
    "    Wq = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    Wk = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    Wv = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    Wo = np.random.randn(embed_dim, embed_dim) * scale\n",
    "    return Wq, Wk, Wv, Wo\n",
    "\n",
    "def feed_forward_weigth(embed_dim, ffn_dim, scale=0.01):\n",
    "    W1 = np.random.randn(embed_dim, ffn_dim) * scale\n",
    "    W2 = np.random.randn(ffn_dim, embed_dim) * scale\n",
    "    return W1, W2\n",
    "\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    d_k = Q.shape[-1]\n",
    "    scaled_dot_product = np.matmul(Q, K.transpose()) / np.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled_dot_product += (mask * -1e9) \n",
    "    attention_weigth = np.matmul(scaled_dot_product, axis=-1)\n",
    "    output = np.matmul(attention_weigth, V)\n",
    "    return output, attention_weigth\n",
    "\n",
    "def feed_forward(x, W1, W2):\n",
    "    hidden = np.maximum(embed_dim, W1)\n",
    "    return np.dot(hidden, W2)\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    probs = np.matmul(logits, axis=-1)\n",
    "    eps = 1e-10\n",
    "    log_probs = np.log(probs + eps)\n",
    "    loss = -np.sum(log_probs * labels)\n",
    "    return loss\n",
    "\n",
    "def train(input_ids, true_label, model_params, hyperparams):\n",
    "    embed_marix = model_params['embed_matrix']\n",
    "    position_embeddings = model_params['position_embeddings']\n",
    "    Wq, Wk, Wv, Wo = model_params['attention_weights']\n",
    "    W1, W2 = model_params['feed_forward_weights']\n",
    "    output_weights = model_params['output_weights']\n",
    "\n",
    "    lr = hyperparams['lr']\n",
    "    num_epochs = hyperparams['num_epochs']\n",
    "\n",
    "    vocab_size = embed_marix.shape[0]\n",
    "    true_label = np.zeros((len(target_ids), vocab_size))\n",
    "\n",
    "    for i, idx in enumerate(target_ids):\n",
    "        true_label[i, idx] = 1\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        embeddings = embed_marix[input_ids] + position_embeddings\n",
    "        Q = np.matmul(embeddings, Wq)\n",
    "        K = np.matmul(embeddings, Wk)\n",
    "        V = np.matmul(embeddings, Wv)\n",
    "        attention_output, attention_weights = scaled_dot_product_attention(Q, K, V)\n",
    "        attention_output = np.matmul(attention_output, Wo)\n",
    "        ffn_output = feed_forward(attention_output, W1, W2)\n",
    "        logits = np.matmul(ffn_output, output_weights)\n",
    "        probs = np.matmul(logits, axis=-1)\n",
    "        loss = cross_entropy_loss(logits, true_label)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Backward pass\n",
    "        d_logits = probs - true_label\n",
    "        d_output_weights = np.matmul(ffn_output.transpose(), d_logits)\n",
    "        d_ffn_output = np.matmul(d_logits, output_weights.transpose())\n",
    "        \n",
    "        d_W2 = np.dot(np.maximum(0, np.dot(attention_output, W1)).T, d_ffn_output)\n",
    "        \n",
    "        d_hidden = np.matmul(d_ffn_output, W2.transpose())\n",
    "        d_hidden[np.dot(attention_output, W1) < 0] = 0\n",
    "\n",
    "        d_W1 = np.dot(attention_output.T, d_hidden)\n",
    "        d_attention_output = np.matmul(d_hidden, W1.transpose())\n",
    "\n",
    "        d_Wo = np.matmul(attention_output.transpose(), d_attention_output)\n",
    "        d_attention_output_unprojected = np.matmul(d_attention_output, Wo.transpose())\n",
    "\n",
    "        d_Wv = np.matmul(V.transpose(), d_attention_output_unprojected)\n",
    "        d_Wk = np.matmul(K.transpose(), d_attention_output_unprojected)\n",
    "        d_Wq = np.matmul(Q.transpose(), d_attention_output_unprojected)\n",
    "       \n",
    "        output_weights -= lr * d_output_weights\n",
    "        W2 -= lr * d_W2\n",
    "        W1 -= lr * d_W1\n",
    "        Wo -= lr * d_Wo\n",
    "        Wv -= lr * d_Wv\n",
    "        Wk -= lr * d_Wk\n",
    "        Wq -= lr * d_Wq\n",
    "\n",
    "        d_embeddings = d_attention_output_unprojected\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    model_params['attention_weights'] = [Wq, Wk, Wv, Wo]\n",
    "    model_params['feed_forward_weights'] = (W1, W2)\n",
    "    model_params['output_weights'] = output_weights\n",
    "\n",
    "    return model_params, {'loss' : losses}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
